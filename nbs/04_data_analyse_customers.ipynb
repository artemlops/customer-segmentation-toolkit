{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.analyse_customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-precipitation",
   "metadata": {},
   "source": [
    "# Analyse customers\n",
    "\n",
    "> transactions per user,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-sleeve",
   "metadata": {},
   "source": [
    "### Compute transactions per user\n",
    "\n",
    "> number of purchases made by the user, minimum, maximum, average amounts and total amount spent during all the visits\n",
    "\n",
    "Original section: 4.1.3 Consumer Order Combinations. Original cells: 47-49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-bonus",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/output/03_data_compute_description_keywords/n_purchase_clusters.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e0a816d48838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/output/03_data_compute_description_keywords'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{DATA}/n_purchase_clusters.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mN_PURCHASE_CLUSTERS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'N_PURCHASE_CLUSTERS={N_PURCHASE_CLUSTERS}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/output/03_data_compute_description_keywords/n_purchase_clusters.txt'"
     ]
    }
   ],
   "source": [
    "from featurologists.data.load_split import load_data_csv\n",
    "\n",
    "DATA = '../data/output/03_data_compute_description_keywords'\n",
    "with open(f'{DATA}/n_purchase_clusters.txt', 'r') as f:\n",
    "    N_PURCHASE_CLUSTERS = int(f.read())\n",
    "logging.info(f'N_PURCHASE_CLUSTERS={N_PURCHASE_CLUSTERS}')\n",
    "\n",
    "basket_price = load_data_csv(f'{DATA}/no_live_data__cleaned__purchase_clusters__train.csv')\n",
    "basket_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def build_transactions_per_user(\n",
    "    basket_price: pd.DataFrame,\n",
    "    n_purchase_clusters: int,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    # nb de visites et stats sur le montant du panier / utilisateurs\n",
    "    transactions_per_user = basket_price.groupby(by=['CustomerID'])['Basket Price']\\\n",
    "                                        .agg(['count','min','max','mean','sum'])\n",
    "    for i in range(n_purchase_clusters):\n",
    "        col = 'categ_{}'.format(i)\n",
    "        transactions_per_user.loc[:,col] = basket_price.groupby(by=['CustomerID'])\\\n",
    "                                                        [col].sum() / transactions_per_user['sum']*100\n",
    "    transactions_per_user.reset_index(drop=False, inplace=True)\n",
    "    \n",
    "    last_date = basket_price['InvoiceDate'].max().date()\n",
    "\n",
    "    first_registration = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].min())\n",
    "    last_purchase      = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].max())\n",
    "\n",
    "    test  = first_registration.applymap(lambda x:(last_date - x.date()).days)\n",
    "    test2 = last_purchase.applymap(lambda x:(last_date - x.date()).days)\n",
    "\n",
    "    transactions_per_user.loc[:, 'LastPurchase'] = test2.reset_index(drop = False)['InvoiceDate']\n",
    "    transactions_per_user.loc[:, 'FirstPurchase'] = test.reset_index(drop = False)['InvoiceDate']\n",
    "\n",
    "    return transactions_per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_per_user = build_transactions_per_user(basket_price, n_purchase_clusters=N_PURCHASE_CLUSTERS)\n",
    "transactions_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def compute_n_customers_with_unique_purchase(transactions_per_user: pd.DataFrame):\n",
    "    return transactions_per_user[transactions_per_user['count'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = compute_n_customers_with_unique_purchase(transactions_per_user)\n",
    "n2 = transactions_per_user.shape[0]\n",
    "print(\"nb. de clients avec achat unique: {:<2}/{:<5} ({:<2.2f}%)\".format(n1,n2,n1/n2*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-ability",
   "metadata": {},
   "source": [
    "### Analyse customers distribution\n",
    "\n",
    "> PCA over customers\n",
    "\n",
    "Original section: 4.2 Creation of customers categories. Original cells: 50-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def convert_customers_df_to_np(\n",
    "    transactions_per_user: pd.DataFrame,\n",
    "    n_purchase_clusters: int,\n",
    ") -> np.ndarray:\n",
    "    list_cols = ['count','min','max','mean'] + [f'categ_{i}' for i in range(n_purchase_clusters)]\n",
    "    matrix = transactions_per_user[list_cols].to_numpy()\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def analyse_customers_pca(\n",
    "    matrix: np.ndarray,\n",
    "    n_components=None,\n",
    ") -> pd.DataFrame:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(matrix)\n",
    "    # print('variables mean values: \\n' + 90*'-' + '\\n' , scaler.mean_)\n",
    "    scaled_matrix = scaler.transform(matrix)\n",
    "    \n",
    "    pca = PCA()\n",
    "    pca.fit(scaled_matrix)\n",
    "    #pca_samples = pca.transform(scaled_matrix)\n",
    "    \n",
    "    return scaled_matrix, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_customers_pca(matrix: np.ndarray, pca: PCA):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    sns.set(font_scale=1)\n",
    "    plt.step(range(matrix.shape[1]), pca.explained_variance_ratio_.cumsum(), where='mid',\n",
    "             label='cumulative explained variance')\n",
    "    sns.barplot(np.arange(1,matrix.shape[1]+1), pca.explained_variance_ratio_, alpha=0.5, color = 'g',\n",
    "                label='individual explained variance')\n",
    "    plt.xlim(0, 10)\n",
    "\n",
    "    ax.set_xticklabels([s if int(s.get_text())%2 == 0 else '' for s in ax.get_xticklabels()])\n",
    "\n",
    "    plt.ylabel('Explained variance', fontsize = 14)\n",
    "    plt.xlabel('Principal components', fontsize = 14)\n",
    "    plt.legend(loc='best', fontsize = 13);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = convert_customers_df_to_np(transactions_per_user, N_PURCHASE_CLUSTERS)\n",
    "scaled_matrix, pca = analyse_customers_pca(matrix)\n",
    "plot_customers_pca(matrix, pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-tobacco",
   "metadata": {},
   "source": [
    "### Analyse customers categories\n",
    "\n",
    "> build customers clusters via Kmeans\n",
    "\n",
    "Original section: 4.2.2 Creation of customer categories. Original cells: 54-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def compute_customer_clusters(\n",
    "    scaled_matrix: np.ndarray,\n",
    "    n_clusters: int,\n",
    ") -> np.ndarray:   \n",
    "    kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=100)\n",
    "    kmeans.fit(scaled_matrix)\n",
    "    clusters = kmeans.predict(scaled_matrix)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CUSTOMER_CLUSTERS = 11\n",
    "\n",
    "clusters_clients = compute_customer_clusters(scaled_matrix, N_CUSTOMER_CLUSTERS)\n",
    "print(pd.DataFrame(pd.Series(clusters_clients).value_counts(), columns = ['nb. de clients']).T)\n",
    "\n",
    "silhouette_avg = silhouette_score(scaled_matrix, clusters_clients)\n",
    "print('score de silhouette: {:<.3f}'.format(silhouette_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurologists.data.analyse_purchases import plot_silhouette\n",
    "\n",
    "sample_silhouette_values = silhouette_samples(scaled_matrix, clusters_clients)\n",
    "plot_silhouette(N_CUSTOMER_CLUSTERS, [-0.15, 0.55], len(scaled_matrix), sample_silhouette_values, clusters_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_customer_categories(\n",
    "    scaled_matrix: np.ndarray,\n",
    "    clusters_clients: np.ndarray,\n",
    "    n_customer_clusters: int,\n",
    "):\n",
    "    mat = pd.DataFrame(scaled_matrix)\n",
    "    mat['cluster'] = pd.Series(clusters_clients)\n",
    "\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_context(\"notebook\", font_scale=1, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "    LABEL_COLOR_MAP = {0:'r', 1:'tan', 2:'b', 3:'k', 4:'c', 5:'g', 6:'deeppink', 7:'skyblue', 8:'darkcyan', 9:'orange',\n",
    "                       10:'yellow', 11:'tomato', 12:'seagreen'}\n",
    "    label_color = [LABEL_COLOR_MAP[l] for l in mat['cluster']]\n",
    "\n",
    "    fig = plt.figure(figsize = (12,10))\n",
    "    increment = 0\n",
    "    for ix in range(6):\n",
    "        for iy in range(ix+1, 6):   \n",
    "            increment += 1\n",
    "            ax = fig.add_subplot(4,3,increment)\n",
    "            ax.scatter(mat[ix], mat[iy], c= label_color, alpha=0.5) \n",
    "            plt.ylabel('PCA {}'.format(iy+1), fontsize = 12)\n",
    "            plt.xlabel('PCA {}'.format(ix+1), fontsize = 12)\n",
    "            ax.yaxis.grid(color='lightgray', linestyle=':')\n",
    "            ax.xaxis.grid(color='lightgray', linestyle=':')\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "\n",
    "            if increment == 12: break\n",
    "        if increment == 12: break\n",
    "\n",
    "    #_______________________________________________\n",
    "    # I set the legend: abreviation -> airline name\n",
    "    comp_handler = []\n",
    "    for i in range(n_customer_clusters):\n",
    "        comp_handler.append(mpatches.Patch(color = LABEL_COLOR_MAP[i], label = i))\n",
    "\n",
    "    plt.legend(handles=comp_handler, bbox_to_anchor=(1.1, 0.9), \n",
    "               title='Cluster', facecolor = 'lightgrey',\n",
    "               shadow = True, frameon = True, framealpha = 1,\n",
    "               fontsize = 13, bbox_transform = plt.gcf().transFigure)\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_customer_categories(scaled_matrix, clusters_clients, N_CUSTOMER_CLUSTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-webster",
   "metadata": {},
   "source": [
    "Original cells 59-61:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def add_customer_clusters_info(\n",
    "    transactions_per_user: pd.DataFrame,\n",
    "    clusters_clients: np.ndarray,\n",
    "):\n",
    "    selected_customers = transactions_per_user.copy(deep = True)\n",
    "    selected_customers.loc[:, 'cluster'] = clusters_clients\n",
    "    \n",
    "    return selected_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_customers_df = add_customer_clusters_info(transactions_per_user, clusters_clients)\n",
    "selected_customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def compute_aggregated_customer_clusters_info(\n",
    "    selected_customers: pd.DataFrame,\n",
    "    n_purchase_clusters: int,\n",
    "    n_customer_clusters: int,\n",
    "    categ_threshold: int = 40,\n",
    "):\n",
    "    merged_df = pd.DataFrame()\n",
    "    for i in range(n_customer_clusters):\n",
    "        test = pd.DataFrame(selected_customers[selected_customers['cluster'] == i].mean())\n",
    "        test = test.T.set_index('cluster', drop = True)\n",
    "        test['size'] = selected_customers[selected_customers['cluster'] == i].shape[0]\n",
    "        merged_df = pd.concat([merged_df, test])\n",
    "\n",
    "    merged_df.drop('CustomerID', axis = 1, inplace = True)\n",
    "    \n",
    "    merged_df = merged_df.sort_values('sum')\n",
    "    \n",
    "    liste_index = []\n",
    "    for i in range(n_purchase_clusters):\n",
    "        column = 'categ_{}'.format(i)\n",
    "        # XXX: Here we changed the constant: 45 -> categ_threshold (see check 'merged_df[column] > 40' below)\n",
    "        liste_index.append(merged_df[merged_df[column] > categ_threshold].index.values[0])\n",
    "    liste_index_reordered = liste_index\n",
    "    set_index = set(liste_index)\n",
    "    liste_index_reordered += [ s for s in merged_df.index if s not in set_index]\n",
    "    merged_df = merged_df.reindex(index = liste_index_reordered)\n",
    "    merged_df = merged_df.reset_index(drop = False)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = compute_aggregated_customer_clusters_info(selected_customers_df, N_PURCHASE_CLUSTERS, N_CUSTOMER_CLUSTERS)\n",
    "print('number of customers:', merged_df['size'].sum())\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# TODO: plot radarchart\n",
    "# I'm getting a weird error:\n",
    "# ValueError: The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of ticklabels (5)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
